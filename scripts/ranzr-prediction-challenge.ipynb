{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.applications.densenet import DenseNet121 \nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D \nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras import backend as K \nfrom tensorflow.keras.models import load_model\nimport os, sys\nimport cv2\nimport random\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROOT_DIR = \nDATA_SETS = '../input/ranzcr-clip-catheter-line-classification'\n#SCRIPTS = ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets_list = os.listdir(DATA_SETS)\ndatasets_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = os.path.join(DATA_SETS, 'train')\nsubmission = os.path.join(DATA_SETS,'sample_submission.csv')\ntest = os.path.join(DATA_SETS, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_SETS+'/train.csv')\nprint(f'Train Data CSV: {train_df.shape[0]}')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(submission)\nprint(f'Sub CSV: {sub_df.shape[0]}')\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label column names\nlabel_cols = list(sub_df.columns[1:])\nimage_labels = train_df[label_cols].values # will be used for train validation splitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count up the number of instances of each class (drop non-class columns from the counts) \nclass_counts = train_df.sum().drop(['StudyInstanceUID','PatientID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we plot the distribution of patients to check if there is any class imbalance in the dataset\ndef plot_class_distributions(values, index):\n    sns.barplot(x=values, y=index)\n    plt.title('Distribution of classes for the patients')\n    plt.xlabel('Patient Count', fontsize=15)\n    plt.ylabel('Catheter Position', fontsize=15)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_class_distributions(class_counts.values, class_counts.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = DATA_SETS + \"/train/\" + train_df['StudyInstanceUID'] + '.jpg'   \ntest_images = DATA_SETS + \"/test/\" + sub_df['StudyInstanceUID'] + '.jpg'\nlen(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_image = os.path.join(DATA_SETS, \"train_annotations.csv\")\ndata_image = pd.read_csv(data_image)\ndata_image.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display images randomly on a grid\ndef display_images(image_ids, labels):\n    fig = plt.figure(figsize = (16,12))\n    \n    for index, (image_id, label) in enumerate(zip(image_ids,labels)):\n        plt.subplot(3,3, index+1)\n        image = image_id + '.jpg'\n        image = mpimg.imread(os.path.join(DATA_SETS, \"train\", image))\n        plt.title(label, fontsize=12)\n        plt.imshow(image,cmap='Greys')\n    \n    fig.tight_layout()\n    plt.show()    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = data_image.sample(9)\nimage_ids = tmp_train[\"StudyInstanceUID\"].values\nlabels = tmp_train['label'].values\ndisplay_images(image_ids, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we check for any kinds of data leakage between any two data sets, train-test, train-valid, valid-test\ndef check_for_leakage(df1, df2, patient_col):\n    \n    df1_unique = set(df1[patient_col])\n    df2_unique = set(df2[patient_col])\n    \n    common_patients = df1_unique.intersection(df2_unique)\n    \n    return True if len(common_patients) > 0 else False\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_for_leakage(train_df, sub_df, 'StudyInstanceUID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for making validation set from given train set\ndef make_val_set(data, val_size):\n    val_patientid = random.sample(list(train_df['PatientID'].unique()),int(val_size*len(train_df['PatientID'].unique())))\n    df_train = data[~data['PatientID'].isin(val_patientid)]\n    df_val = data[data['PatientID'].isin(val_patientid)]\n    return df_train, df_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_val = make_val_set(train_df, val_size=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_for_leakage(df_train, df_val, 'PatientID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train Data Size: {df_train.shape[0]}')\nprint(f'Validation Data Size: {df_val.shape[0]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMAGE_DIR = DATA_SETS + '/train/'\nTEST_IMAGE_DIR = DATA_SETS + '/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# without augmentation\ndef get_train_generator(df, image_dir, image_id, label_names, shuffle=True, batch_size=32, seed=1, target_width=256, target_height=256):\n    print('Train Generator Preparation: ')\n    \n    # first we normalize the images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization=True\n    )\n    \n    # next we flow from data frame with a certain batch size.\n    # This flows the images from the directory\n    generator = image_generator.flow_from_dataframe(\n        dataframe=df,\n        directory=image_dir,\n        x_col=image_id,\n        y_col=label_names,\n        class_mode=\"raw\",\n        classes=label_names,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        seed=1,\n        target_size=(target_width, target_height)\n    )\n    \n    return generator\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create image generator\ndef get_image_generator(train_df, image_dir, image_id, label_names, shuffle=True, batch_size=32, seed=1, target_width=256, target_height=256, sample_size=100):\n    # generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df,\n        directory=image_dir,\n        x_col=image_id,\n        y_col=label_names,\n        class_mode='raw',\n        batch_size=sample_size,\n        shuffle=shuffle,\n        target_size=(target_width, target_height)\n    )\n    \n    batch = raw_train_generator.next() \n    data_sample = batch[0] \n    \n    # use sample to fit mean and std for test set generator \n    image_generator = ImageDataGenerator( \n        featurewise_center=True, \n        featurewise_std_normalization= True) \n    \n    # fit generator to sample from training data \n    image_generator.fit(data_sample)\n    \n    return image_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator(df, image_dir, x_col, y_cols, image_generator, batch_size=32, seed=1, target_width = 256, target_height = 256):\n    # get valid generator \n    generator = image_generator.flow_from_dataframe( \n        dataframe=df, \n        directory=image_dir, \n        x_col=x_col, y_col=y_cols, \n        class_mode=\"raw\", \n        batch_size=batch_size, \n        shuffle=False, \n        seed=seed, \n        target_size=(target_width,target_height)\n    )\n    \n    return generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn, ext='.jpg'):\n    return fn+ext\n\ntrain_df_splitted['StudyInstanceUID'] = train_df_splitted['StudyInstanceUID'].apply(append_ext)\nvalid_df['StudyInstanceUID'] = valid_df['StudyInstanceUID'].apply(append_ext)\nsub_df['StudyInstanceUID'] = sub_df['StudyInstanceUID'].apply(append_ext)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = get_train_generator(train_df_splitted, TRAIN_IMAGE_DIR, \"StudyInstanceUID\", label_cols)\nraw_image_generator = get_image_generator(train_df_splitted, TRAIN_IMAGE_DIR, \"StudyInstanceUID\", label_cols)\nvalid_generator = get_generator(valid_df, TRAIN_IMAGE_DIR, \"StudyInstanceUID\", label_cols, raw_image_generator)\ntest_generator= get_generator(sub_df, TEST_IMAGE_DIR, \"StudyInstanceUID\", label_cols, raw_image_generator)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}